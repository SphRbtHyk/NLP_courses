{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5398db",
   "metadata": {},
   "source": [
    "# Analyse en constituants à l'aide de Stanza\n",
    "\n",
    "Le but de ce TP est de découvrir une autre bibliothèque permettant l'annotation linguistique et syntaxique en Python, [stanza](https://stanfordnlp.github.io/stanza/). Nous nous en servirons tout particulièrement pour sa possibilité de réaliser l'analyse en constituants. **Malheureusement, il n'existe pas encore de modèles pour réaliser l'analyse de constituant en français, nous allons donc travailler avec un texte en anglais.**\n",
    "Téléchargez le fichier texte associé dans le GitHub, qui va être stocké dans le dossier `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519106f",
   "metadata": {},
   "source": [
    "## Premier pas avec la bibliothèque\n",
    "\n",
    "Utilisez `pip` pour install `stanza`.\n",
    "`stanza` possède une interface à la fois **similaire** mais aussi **différente** par rapport à `spacy`, car elle ne travaille pas au niveau du `token` mais au niveau de la phrase en elle-même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb585b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 09:41:53 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d91874dc93346d18aa49854d42d6e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 09:41:53 INFO: Downloaded file to /Users/sophrobhayek/stanza_resources/resources.json\n",
      "2025-12-02 09:41:53 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-12-02 09:41:54 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2025-12-02 09:41:54 INFO: Using device: cpu\n",
      "2025-12-02 09:41:54 INFO: Loading: tokenize\n",
      "2025-12-02 09:41:54 INFO: Loading: mwt\n",
      "2025-12-02 09:41:54 INFO: Loading: pos\n",
      "2025-12-02 09:41:54 INFO: Loading: lemma\n",
      "2025-12-02 09:41:54 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# Création d'une pipeline qui permet la tokenisation, le POS, le lemme.\n",
    "nlp = stanza.Pipeline('en', processors='tokenize,pos,lemma')\n",
    "\n",
    "sentence = \"the dog is happy\"\n",
    "\n",
    "doc = nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "318703d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phrase : the dog is happy\n",
      "------------------------------\n",
      "Mot : the        | POS : DET   | Lemme : the\n",
      "Mot : dog        | POS : NOUN  | Lemme : dog\n",
      "Mot : is         | POS : AUX   | Lemme : be\n",
      "Mot : happy      | POS : ADJ   | Lemme : happy\n"
     ]
    }
   ],
   "source": [
    "# Itération sur les phrases\n",
    "for phrase in doc.sentences:\n",
    "    print(f\"\\nPhrase : {phrase.text}\")\n",
    "    print(\"-\" * 30)\n",
    "    # Itération sur les mots\n",
    "    for mot in phrase.words:\n",
    "        print(f\"Mot : {mot.text:10} | POS : {mot.pos:5} | Lemme : {mot.lemma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff40aa2",
   "metadata": {},
   "source": [
    "## Annotation linguistique avec stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b1b61",
   "metadata": {},
   "source": [
    "**Exercice**:\n",
    "\n",
    "Soit le texte présent dans `data/farewell_arms.txt`.\n",
    "\n",
    "1. Chargez l'ensemble du texte.\n",
    "2. En faisant l'hypothèse que 1 mot = 1 espace, comptez le nombre de mots dans la phrase.\n",
    "3. En utilisant les lemmes, réalisez un dictionnaire qui contient pour chaque **mot distinct** (au sens du lemme) le nombre d'occurences dans le texte.\n",
    "4. Retournez les mots les plus fréquents du texte.\n",
    "5. Retournez grâce à Stanza le nombre de \"NOUN\" dans le texte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c0f28c",
   "metadata": {},
   "source": [
    "## Analyse en constituant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1bc9a8",
   "metadata": {},
   "source": [
    "Stanza permet, contrairement à `spaCy`, de réaliser l'analyse en constituants d'une phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43edd312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 13:40:02 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b415956317492186b16523b07f1471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 13:40:02 INFO: Downloaded file to /Users/sophrobhayek/stanza_resources/resources.json\n",
      "2025-12-02 13:40:02 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-12-02 13:40:03 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| mwt          | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "======================================\n",
      "\n",
      "2025-12-02 13:40:03 INFO: Using device: cpu\n",
      "2025-12-02 13:40:03 INFO: Loading: tokenize\n",
      "2025-12-02 13:40:03 INFO: Loading: mwt\n",
      "2025-12-02 13:40:03 INFO: Loading: pos\n",
      "2025-12-02 13:40:04 INFO: Loading: constituency\n",
      "2025-12-02 13:40:04 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT (S (NP (DT This)) (VP (VBD was) (NP (DT a) (NN test)))))\n",
      "((S (NP (DT This)) (VP (VBD was) (NP (DT a) (NN test)))),)\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency')\n",
    "doc = nlp('This was a test')\n",
    "for sentence in doc.sentences:\n",
    "    print(sentence.constituency)\n",
    "\n",
    "# Il est possible d'accéder de manière récursive aux différents étages de l'arbre\n",
    "tree = doc.sentences[0].constituency\n",
    "print(tree.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca736006",
   "metadata": {},
   "source": [
    "La bibliothèque `nltk` permet de visualiser sous format d'arbre le parsing en constituant au format `ascii`. Installez `nltk` et la bibliothèque complémentaire `svgling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cb81beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"264px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,168.0,264.0\" width=\"168px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ROOT</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"28.5714%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">This</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.2857%\" y1=\"20px\" y2=\"48px\" /><svg width=\"71.4286%\" x=\"28.5714%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP</text></svg><svg width=\"33.3333%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">was</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.6667%\" y1=\"20px\" y2=\"48px\" /><svg width=\"66.6667%\" x=\"33.3333%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"40%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">a</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20%\" y1=\"20px\" y2=\"48px\" /><svg width=\"60%\" x=\"40%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">test</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.6667%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.2857%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('ROOT', [Tree('S', [Tree('NP', [Tree('DT', ['This'])]), Tree('VP', [Tree('VBD', ['was']), Tree('NP', [Tree('DT', ['a']), Tree('NN', ['test'])])])])])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tree import Tree\n",
    "\n",
    "Tree.fromstring(str(sentence.constituency))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fabf15",
   "metadata": {},
   "source": [
    "**Exercices**:\n",
    "\n",
    "1. Soit la phrase: \"the dog that is pursuing the cat that yells strongly\". Représentez l'arbre sous forme de représentation graphique. Trouvez l'abbréviation pour les clauses subordonnées et donnez leur nombre dans la phrase d'exemple.\n",
    "2. Soit la phrase \"I see Mary in my pajama\". Rappelez le problème possible avec l'analyse de ce type de phrase, et observez quelle solution propose Stanza en générant une représentation graphique de l'arbre. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422caf81",
   "metadata": {},
   "source": [
    "**Exercices**:\n",
    "\n",
    "En reprenant le texte d'Hemingway:\n",
    "1. En reprenant le texte d'Hemingway, comptez les groupes nominaux.\n",
    "2. Comptez pour chaque phrase le nombre d'enfants au premier niveau.\n",
    "3. Trouvez toutes les occurrences de la structure \"NP PP\".\n",
    "3. Calculez le nombre moyen de clause subordonnée par phrase. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
