{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP : Annotations en parties du discours avec SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy est une bibliothèque Python qui permet de réaliser de l'analyse grammaticale et syntaxique.\n",
    "\n",
    "**Exercices**:\n",
    "1. Installez SpaCy grâce à `pip` et téléchargez le modèle français `fr_core_news_sm` (voir ci-dessous pour la marche à suivre).\n",
    "2. Importez SpaCy et chargez le modèle français."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.8.0/fr_core_news_lg-3.8.0-py3-none-any.whl (571.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.8/571.8 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fr-core-news-lg\n",
      "Successfully installed fr-core-news-lg-3.8.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commandes d'installation à exécuter dans le terminal pour obtenir un modèle donné:\n",
      "!python -m spacy download fr_core_news_sm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "print(\"Commandes d'installation à exécuter dans le terminal pour obtenir un modèle donné:\")\n",
    "print(\"!python -m spacy download fr_core_news_sm\")\n",
    "print(\"\")\n",
    "\n",
    "# Chargement d'un modèle donné\n",
    "nlp = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2: Analyse d'une phrase\n",
    "\n",
    "Spacy permet grâce à son objet `nlp` d'appliquer une pipeline de traitement à un texte, et qui permet d'extraire ainsi son lemme, son analyse morphologique, et son POS.\n",
    "\n",
    "On s'en sert ainsi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse détaillée de la phrase:\n",
      "------------------------------------------------------------\n",
      "Texte: Le         Lemme: le         POS: DET      DEP: det         \n",
      "Texte: chat       Lemme: chat       POS: NOUN     DEP: nsubj       \n",
      "Texte: noir       Lemme: noir       POS: ADJ      DEP: amod        \n",
      "Texte: dort       Lemme: dormir     POS: VERB     DEP: ROOT        \n",
      "Texte: paisiblement Lemme: paisiblement POS: ADV      DEP: advmod      \n",
      "Texte: sur        Lemme: sur        POS: ADP      DEP: case        \n",
      "Texte: le         Lemme: le         POS: DET      DEP: det         \n",
      "Texte: vieux      Lemme: vieux      POS: ADJ      DEP: amod        \n",
      "Texte: canapé     Lemme: canapé     POS: NOUN     DEP: obl:arg     \n",
      "Texte: .          Lemme: .          POS: PUNCT    DEP: punct       \n"
     ]
    }
   ],
   "source": [
    "phrase = \"Le chat noir dort paisiblement sur le vieux canapé.\"\n",
    "\n",
    "doc = nlp(phrase)\n",
    "\n",
    "print(\"Analyse détaillée de la phrase:\")\n",
    "print(\"-\" * 60)\n",
    "for token in doc:\n",
    "    print(f\"Texte: {token.text:10} Lemme: {token.lemma_:10} POS: {token.pos_:8} DEP: {token.dep_:12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercices**:\n",
    "\n",
    "1. Soit la phrase \"Le chien dort dehors et le chat le regarde\".\n",
    "2. Comptez le nombre de `NOUN` dans la phrase grâce à Spacy, et calculez manuellement l'accuracy.\n",
    "3. Créez une fonction `count_pos_freq` qui étant donné un texte : \n",
    "{\"NOUN\": n1, \"VERB\": n2}... qui compte la fréquence du nombre d'occurences de chaque POS dans la phrase.\n",
    "4. **Bonus**: Créez une fonction `liste_lemme` qui étant donné un texte fait une liste des lemmes présents dans la phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte: Le         Lemme: le         POS: DET      DEP: det         \n",
      "Texte: chien      Lemme: chien      POS: NOUN     DEP: nsubj       \n",
      "Texte: dort       Lemme: dormir     POS: VERB     DEP: ROOT        \n",
      "Texte: dehors     Lemme: dehors     POS: ADP      DEP: advmod      \n",
      "Texte: et         Lemme: et         POS: CCONJ    DEP: cc          \n",
      "Texte: le         Lemme: le         POS: DET      DEP: det         \n",
      "Texte: chat       Lemme: chat       POS: NOUN     DEP: conj        \n",
      "Texte: le         Lemme: le         POS: DET      DEP: obj         \n",
      "Texte: regarde    Lemme: regarde    POS: NOUN     DEP: xcomp       \n"
     ]
    }
   ],
   "source": [
    "### Question 1\n",
    "\n",
    "phrase = \"Le chien dort dehors et le chat le regarde\"\n",
    "\n",
    "doc = nlp(phrase)\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"Texte: {token.text:10} Lemme: {token.lemma_:10} POS: {token.pos_:8} DEP: {token.dep_:12}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nouns: 1\n"
     ]
    }
   ],
   "source": [
    "### Question 2\n",
    "number_noun = 0\n",
    "for token in doc:\n",
    "    if token.pos_ == \"NOUN\":\n",
    "        number_noun += 1\n",
    "\n",
    "print(f\"Number of nouns: {number_noun}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DET': 0.16666666666666666,\n",
       " 'NOUN': 0.16666666666666666,\n",
       " 'VERB': 0.3333333333333333,\n",
       " 'ADV': 0.16666666666666666,\n",
       " 'CCONJ': 0.16666666666666666}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question 3 ###\n",
    "phrase = \"Le chien dort dehors et le chat le regarde\"\n",
    "\n",
    "doc = nlp(phrase)\n",
    "\n",
    "def count_pos_freq(phrase: str) -> dict[str, int]:\n",
    "    \"\"\"Given a sentence, compute the number\n",
    "    of ocurences of all the encountered POS.\n",
    "\n",
    "    Args:\n",
    "        phrase (str): The sentence to analyze.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, int]: The number per POS.\n",
    "    \"\"\"\n",
    "    doc = nlp(phrase)\n",
    "    nbr_word = len(phrase.split())\n",
    "\n",
    "    freq_dict = {}\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ in freq_dict:\n",
    "            freq_dict[token.pos_] += 1/nbr_word\n",
    "        else:\n",
    "            freq_dict[token.pos_] = 1/nbr_word\n",
    "\n",
    "    return freq_dict\n",
    "\n",
    "count_pos_freq(phrase=\"Le chien mange bien et dort\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 : Application pour l'étude d'un texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercices**:\n",
    "1. Chargez l'extrait de Victor Hugo fourni dans le fichier `data/notre_dame.txt`.\n",
    "2. Combien de phrases contient-il ? Combien de tokens (on utilisera pour définir tokens = mots et phrases=séparées par une ponctuation.)?\n",
    "3. Proposez une pipeline de text-cleaning adéquate après avoir visualisé les données.\n",
    "4. Appliquez la fonction `count_pos_freq` sur le texte (ou une partie du texte, calibrez en fonction des performances de votre machine).\n",
    "5. Chargez maintenant l'extrait `data/trois_mousquetaires.txt` d'Alexandre Dumas et appliquez la même méthode de nettoyage de données que pour le texte de Victor Hugo.\n",
    "6. Appliquez `count_pos_freq` et comparez la différence de style entre les deux ouvrages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de phrases: 339\n",
      "Nombre de token: 4822\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "#### Question 1 ####\n",
    " \n",
    "with open(\"data/notre_dame.txt\") as f:\n",
    "    notre_dame = f.read()\n",
    "\n",
    "# Quick text cleaning\n",
    "notre_dame = notre_dame.replace(\"\\n\", \" \")\n",
    "\n",
    "#### Question 2 ####\n",
    "# On considère une phrase comme étant séparée par une ponctuation\n",
    "# On découpe les phrases selon chacun des signes\n",
    "PUNCTUATION = [\".\",\"!\",\"?\",\";\"]\n",
    "\n",
    "nombre_phrases = 1\n",
    "\n",
    "for letter in notre_dame:\n",
    "    if letter in PUNCTUATION:\n",
    "        nombre_phrases += 1\n",
    "\n",
    "for punct in PUNCTUATION:\n",
    "    notre_dame = notre_dame.replace(punct, \" \")\n",
    "\n",
    "print(f\"Nombre de phrases: {nombre_phrases}\")\n",
    "print(f\"Nombre de token: {len(notre_dame.split())}\")\n",
    "\n",
    "### Question 3 ###\n",
    "CLEANING = [\"--\", \"_\"]\n",
    "notre_dame = notre_dame.lower()\n",
    "\n",
    "for symbol in CLEANING:\n",
    "    notre_dame = notre_dame.replace(symbol, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Question 4 ####\n",
    "\n",
    "freq_notre_dame = count_pos_freq(notre_dame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On réalise le même traitement pour les trois mousquetaires\n",
    "\n",
    "# On met dans une fonction toutes les étapes de nettoyage que l'on a réalisé\n",
    "\n",
    "def clean_text(input_path: str, symbols_to_clean: list[str] = [\"--\", \"_\", \"\\n\"]) -> str:\n",
    "    \"\"\"Given an input file, load the file and performs its cleaning.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): The path to the data file.\n",
    "        symbols_to_clean (list[str]): The list of symbols to remove from\n",
    "            the string.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned up file.\n",
    "    \"\"\"\n",
    "    with open(input_path) as f:\n",
    "        text = f.read()\n",
    "\n",
    "    for symbol in symbols_to_clean:\n",
    "        text = text.replace(symbol, \" \")\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "trois_mousquetaires = clean_text(\"data/trois_mousquetaires.txt\")\n",
    "\n",
    "freq_mousquetaire = count_pos_freq(trois_mousquetaires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente 16.9% de NOUN que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente 29.0% de ADJ que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente 64.8% de SPACE que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente 5.4% de DET que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente -37.5% de PRON que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente -31.8% de VERB que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente -69.2% de ADV que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente 25.1% de NUM que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente -16.1% de CCONJ que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente -92.3% de SCONJ que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente 11.6% de ADP que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente 30.6% de PROPN que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente -55.8% de PUNCT que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente -30.8% de AUX que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente -161.5% de X que 'Les trois mousquetaires'\n",
      "----\n",
      "----\n",
      "'Le Bossu de Notre Dame' présente -728.2% de INTJ que 'Les trois mousquetaires'\n"
     ]
    }
   ],
   "source": [
    "### Comparaison entre les 2 ouvrages: on va créer un nouveau dictionnaire comparaison qui va calculer la différence relative entre les trois mousquetaires et Victor Hugo \n",
    "comparison = {}\n",
    "for key, value in freq_notre_dame.items():\n",
    "    comparison[key] = (value - freq_mousquetaire[key])/value*100\n",
    "\n",
    "\n",
    "for key, value in comparison.items():\n",
    "    print(\"----\")\n",
    "    print(\"----\")\n",
    "    print(f\"'Le Bossu de Notre Dame' présente {round(value, 1)}% de {key} que 'Les trois mousquetaires'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
